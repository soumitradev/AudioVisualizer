{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we have a function $f(t)$. Note how this function varies with time, similar to an audio signal. The domain of this function is from $t=0$ to $t=\\infty$. Now, we want to transform this function such that the domain changes from time to that of frequency.\n",
    "\n",
    "The fourier transform when applied to audio signals does exactly this. \n",
    "\n",
    "The frequencies are represented as a sum of sinusoidal waves with an amplitude and frequency each.\n",
    "\n",
    "So, according to the fourier transform, the amplitude of the $\\frac{k}{n}^{th}$ frequency is given by:\n",
    "\n",
    "$$X_K = \\sum^{N-1}_{n = 0} x_n \\cdot e^{-2 \\pi i \\cdot \\frac{Kn}{N}}$$\n",
    "\n",
    "where\n",
    "\n",
    "$x_n =$ amplitude of sample taken\n",
    "\n",
    "$N = $ number of frequencies we get from fourier transform\n",
    "\n",
    "$\\frac{K}{N} =$ frequency that we measure for any $K$\n",
    "\n",
    "$n =$ n^{th} sample in audio signal\n",
    "\n",
    "On using Euler's formula, ($e^{ix} = cos(x) + i sin(x)$) we get:\n",
    "\n",
    "$$X_K = \\sum^{N-1}_{n=0} x_n \\cdot [cos(\\frac{-2 \\pi Kn}{N}) + i sin(\\frac{-2 \\pi Kn}{N})]$$\n",
    "\n",
    "Now, we'll make this expression a little simpler.\n",
    "\n",
    "Let $\\frac{2 \\pi K n}{N}$ be some $b_n$\n",
    "\n",
    "Then, on expanding, we can express our sum as:\n",
    "\n",
    "$$X_K = [x_0 cos(b_0) + x_1 cos(b_1) + x_2 cos(b_2) \\cdots] - i [x_0 sin(b_0) + x_1 sin(b_1) + x_2 sin(b_2) \\cdots]$$\n",
    "\n",
    "Further compressing this,\n",
    "\n",
    "$$X_K = A_K + i B_K$$\n",
    "\n",
    "Here, we get $X_K$ as a complex number. Since this can be plotten on the complex plane and is varying by time, it can be expressed as a phasor for a wave. This is where we move from the abstract idea of $X_K$ to an actual wave.\n",
    "\n",
    "Now, in phasor notation, this $X_K$ can be expressed as\n",
    "\n",
    "$$r = \\sqrt{A_K^2 + B_K^2}$$\n",
    "\n",
    "$$\\theta = arctan(\\frac{B_K}{A_K})$$\n",
    "\n",
    "We have finally moved from a single sample to a sum of waves. The total number of waves we got is $N$, and the $K^{th}$ sum will have frequency $\\frac{K}{N}$. The end wave we get is a sine wave with amplitude $r$ and phase shift $\\theta$\n",
    "\n",
    "Let's do a DFT manually on a simple example to better understand how this works.\n",
    "\n",
    "Consider a sine wave with amplitude 1, and time period 1 second. We will take 8 samples. The number of samples per second of audio is known as our sampling frequency.\n",
    "\n",
    "Taking 8 samples on our wave, our samples are:\n",
    "\n",
    "| $x$   |   $f(x)$                      |\n",
    "|-------|-------------------------------|\n",
    "| $x_0$ | $f(x_0) = 0$                  |\n",
    "| $x_1$ | $f(x_1) = \\frac{1}{\\sqrt{2}}$ |\n",
    "| $x_2$ | $f(x_2) = 1$                  |\n",
    "| $x_3$ | $f(x_1) = \\frac{1}{\\sqrt{2}}$ |\n",
    "| $x_4$ | $f(x_4) = 0$                  |\n",
    "| $x_5$ | $f(x_1) = \\frac{-1}{\\sqrt{2}}$|\n",
    "| $x_6$ | $f(x_6) = -1$                 |\n",
    "| $x_7$ | $f(x_1) = \\frac{-1}{\\sqrt{2}}$|\n",
    "\n",
    "Note that this is just the signal we have, we haven't done any processing yet. These are the samples that model our curve.\n",
    "\n",
    "Since we have 8 samples, let us calculate all the $X$ values ($X_0, X_1, X_2, \\cdots X_6, X_7$)\n",
    "\n",
    "$$X_0 = \\sum^{N-1}_{n = 0}x_n \\cdot e^{\\frac{-2\\pi iKn}{N}} = \\sum^{N-1}_{n = 0}x_n \\cdot e^{0} = \\sum^{N-1}_{n = 0}x_n = 0$$\n",
    "$$X_1 = \\sum^{N-1}_{n = 0}x_n \\cdot e^{\\frac{-2\\pi iKn}{N}} = \\sum^{N-1}_{n = 0}x_n \\cdot e^{\\frac{-2\\pi in}{N}} = 0 + x_1 \\cdot e^{\\frac{-\\pi}{4}} + x_2 \\cdot e^{\\frac{-\\pi}{2}} + \\cdots = -4i$$\n",
    "$$X_2 = \\sum^{N-1}_{n = 0}x_n \\cdot e^{\\frac{-2\\pi iKn}{N}} = \\sum^{N-1}_{n = 0}x_n \\cdot e^{\\frac{-4\\pi in}{N}} = 0 + x_1 \\cdot e^{\\frac{-\\pi}{2}} + x_2 \\cdot e^{-\\pi} + \\cdots = 0$$\n",
    "$$\\vdots$$\n",
    "$$X_6 = \\sum^{N-1}_{n = 0}x_n \\cdot e^{\\frac{-2\\pi iKn}{N}} = \\sum^{N-1}_{n = 0}x_n \\cdot e^{\\frac{-12\\pi in}{N}} = 0 + x_1 \\cdot e^{\\frac{-3\\pi}{2}} + x_2 \\cdot e^{-3\\pi} + \\cdots = 0$$\n",
    "$$X_7 = \\sum^{N-1}_{n = 0}x_n \\cdot e^{\\frac{-2\\pi iKn}{N}} = \\sum^{N-1}_{n = 0}x_n \\cdot e^{\\frac{-14\\pi in}{N}} = 0 + x_1 \\cdot e^{\\frac{-7\\pi}{4}} + x_2 \\cdot e^{\\frac{-7\\pi}{2}} + \\cdots = 4i$$\n",
    "\n",
    "At the end, we get: \n",
    "\n",
    "| $X$   |Value of $X_k$| $r$  |\n",
    "|-------|--------------|------|\n",
    "| $X_0$ | $0$          | $0$  |\n",
    "| $X_1$ | $-4i$        | $4$  |\n",
    "| $X_2$ | $0$          | $0$  |\n",
    "| $X_3$ | $0$          | $0$  |\n",
    "| $X_4$ | $0$          | $0$  |\n",
    "| $X_5$ | $0$          | $0$  |\n",
    "| $X_6$ | $0$          | $0$  |\n",
    "| $X_7$ | $4i$         | $4$  |\n",
    "\n",
    "But what frequency does $X_K$ correspond to?\n",
    "The frequency resolution is the $\\frac{sampling \\hspace{4pt} frequency}{number \\hspace{4pt} of \\hspace{4pt} samples}$. This is the increment in actual frequency for each increment in $n$. Here, we took 8 samples per second, and we have 8 total samples. So, the frequency increases by $\\frac{8}{8} = 1Hz$ for each increment in $n$.\n",
    "\n",
    "So, $X_0$ is $0Hz$, $X_1$ is $1Hz$, $X_2$ is $2Hz$, and so on.\n",
    "\n",
    "So, we notice that the amplitude of the wave ($r$) is 4 for some reason, and also appears at $X_7$!\n",
    "\n",
    "Why does it reappear at $7Hz$? Well, the fourier transform yields a 2 sided symmetric graph. So, the upper half of the data we have after the fourier transform is an exact copy of the data of the lower half. So, for our application, we simply ignore it. Now, this presents a problem. We can analyse only half of the frequencies as our sampling rate. This half the value of sample rate is called the *Nyquist Limit*. For usual audio signals, the sampling rate is $44100Hz$. This puts our Nyquist limit at $22050Hz$. This is exactly the range of human hearing!\n",
    "\n",
    "Now, why is  the amplitude 4? When we originally made our curve ($1Hz$ sine wave with amplitude 1), we specifically set the amplitude to 1. Why do we get 4? Let us see why this is. But before that, since we threw away half our data, we need to double our current data to preserve information. And we do. The ampilitudes of the *useful* frequencies below the Nyquist Limit are doubled. Now, we have 8! This is nowhere close to 1!\n",
    "\n",
    "Well, we also took 8 samples. So, averaging our data over the 8 samples gives us the correct $1Hz$.\n",
    "\n",
    "Well, we did get the amplitude of our frequency. What about the phase shift?\n",
    "\n",
    "The phase shift for our $X_1$ (which is the only $X$ below Nyquist Limit with a non zero amplitude), is $arctan(\\frac{B_K}{A_K})$. However, our $A_K = 0$ since it's the real part of $X_K$ and our $X_1$ is $-8i$ after the doubling.\n",
    "\n",
    "So, we use the $arccos$ form for the phase angle.\n",
    "\n",
    "$$\\theta = arccos(\\frac{A_K}{\\sqrt{A_K^2 + B_K^2}})$$\n",
    "\n",
    "$$\\theta = arccos(0)$$\n",
    "$$\\theta = \\frac{\\pi}{2} \\hspace{4pt} or \\hspace{4pt} \\frac{3\\pi}{2}$$\n",
    "\n",
    "Now, since our phasor is equal to $-8i$, we know that $\\theta > \\frac{\\pi}{2}$. \n",
    "\n",
    "Hence, our $\\theta = \\frac{3\\pi}{2}$\n",
    "\n",
    "Note that the phase angle is for a *cosine* wave. So factoring in our frequency and phase shift,\n",
    "\n",
    "$$f(t) = 1 \\cdot cos(2\\pi t + \\frac{3\\pi}{2})$$\n",
    "$$f(t) = sin(2\\pi t)$$\n",
    "\n",
    "Now, what we just did is a Discrete Fourier Transform (DFT). This algorithm has a complexity of $\\mathcal{O}(n^2)$. This can be really slow, and we can trade some accuracy for speed if we're dealing with realtime audio.\n",
    "\n",
    "So, there's another algorithm called Fast Fourier Transform (FFT) that programs generally use. FFT has a complexity of $\\mathcal{O}(n\\log{}n)$, which is much faster than DFT.\n",
    "\n",
    "Numpy has an FFT function built into it that we can, and will use.\n",
    "\n",
    "Now, we need to take this mathematical idea and apply it to Audio signals.\n",
    "\n",
    "Most audio files have a sample rate of $44,100Hz$, which we will use. Also, we need to draw a 30 FPS video. We need to process packets as they come in 30 times per second.\n",
    "\n",
    "This might be slow, so we'll use a clever techinque called *interpolation*. We will calculate 15 times per second, and calculate intermediate values in between 2 calculations. So, we calculate 15 times a second, and draw intermediate frames in between them, giving us an effective 30 FPS video.\n",
    "\n",
    "This will also make the video smoother as the bars in the video won't fluctuate as much since an intermediate value is being calculated.\n",
    "\n",
    "So, if we're grabbing 15 parts of a one second clip, which contains 44,100 samples, each time we calculate the FFT, we need to feed it $\\frac{44100}{15} = 2940$ samples.\n",
    "\n",
    "So, we have an audio file of $T$ seconds, we split the $T \\cdot 44100$ samples into $15 \\cdot T$ parts of $2940$ samples each.\n",
    "\n",
    "We know, our frequency resolution is $\\frac{sampling \\hspace{4pt} frequency}{number \\hspace{4pt} of \\hspace{4pt} samples} = \\frac{44,100}{2940} = 15Hz$ which is approximately the frequency difference between the note E2 and F2, which makes our model just perfect to differentiate musical notes!\n",
    "\n",
    "However, this is not what we want. If we have bins of 15Hz width from 0Hz to 22050Hz, we have 1470 bins!\n",
    "\n",
    "We still need to classify these bins better and merge them until we have about 50 bins (which is also the number of bins I have for the audio visualiser I use to customise my desktop).\n",
    "\n",
    "Well, just merge every $\\frac{1470}{50} \\approx 30$ bins right?\n",
    "\n",
    "Well yes, but that'd not be the best way to do this. That *would* divide the frequencies equally, but that's not how human hearing actually works.\n",
    "\n",
    "According to the Weber-Fechner Law, our brain is sensitive to signals logarithmically, not linearly. Which means, that the frequencies need to be put in bins logarithmically to make intuitive sense while listening to it. However, this mapping will take time, so instead, we use a rough approximation using a square root graph instead of a logarithmic graph.\n",
    " \n",
    "So, since our bins maxx out at 50, we'll need a square root that varies from 0 to 1 multiplied with the maximum number of bins, 50.\n",
    "\n",
    "So, we put our frequency in the square root. Since this needs to vary from 0 to 1, we divide it with the maximum possible frequency first, or our Nyquist Limit. Also, since we want it to be an integer, we'll floor the square root.\n",
    "\n",
    "So, we get:\n",
    "\n",
    "$$B_i = 50 \\cdot floor(\\sqrt{\\frac{X_K}{X_{max}}})$$\n",
    "\n",
    "Note that for every increment in $K$, the frequency increases by $15Hz$, and that the value we get is actually for the lower limit of the $15Hz$ range since we still get 0 amplitude for $X_0$.\n",
    "\n",
    "So, since we have 1470 frequencies to process, we classify each of these into a bin, add up the areas of the original bars, and then render a new bar.\n",
    "\n",
    "Now, we finally have a bar length we can render to represent the frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cmath\n",
    "import math\n",
    "from scipy.io import wavfile\n",
    "import wave\n",
    "# import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from IPython.display import Audio\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define an FFT function that we'll use for analysing audio\n",
    "\n",
    "# Note how we also pass the number of samples as an argument\n",
    "# since we call this function a lot and repeatedly calculating number of samples\n",
    "# (which is a constant) will only slow it down\n",
    "def FFT(stuff, sampling_rate, num_samples):\n",
    "    # Perform an FFT on our audio data and grab the first half\n",
    "    # since the second half is a mirror of the first in a fourier transform\n",
    "    F = list(np.fft.fft(stuff))[:round(num_samples/2)]\n",
    "\n",
    "    # Calculate sampling resolution\n",
    "    sampling_resolution = sampling_rate/num_samples\n",
    "\n",
    "    # For every frquency we get, double the data and get the magnitude of the vector,\n",
    "    # and divide by number of samples to get actual amplitude\n",
    "    return [(2*abs(freq)/num_samples, i*sampling_resolution) for i, freq in enumerate(F)]\n",
    "\n",
    "    # Notice how we used a list comprehension (which is faster than a for loop) and enumerate()\n",
    "    # instead of accessing F[i] repeatedly. We are trading memory space for speed.\n",
    "    # However, note that this won't take a whole lot of memory since we work with only around \n",
    "    # 2000 sized lists with pure numbers in it, and that all this memory space is deallocated\n",
    "    # after the function returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "20.55093216896057\n"
    },
    {
     "output_type": "error",
     "ename": "Exception",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-95e492916316>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpacket_num\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sample_rate, data = wavfile.read('./tst1.wav')\n",
    "N = len(data)\n",
    "\n",
    "fps = 15\n",
    "\n",
    "a = time.time()\n",
    "packet_len = int(sample_rate/fps)\n",
    "\n",
    "packeted_data = [data[i*packet_len:(i+1)*packet_len] for i in range(N//packet_len + 1)]\n",
    "fft_ed_data = [FFT(packet, sample_rate, packet_len) for packet in packeted_data]\n",
    "b = time.time()\n",
    "\n",
    "print(b-a)\n",
    "raise Exception\n",
    "for packet_num in range(math.ceil((N*fps)/(fs))):\n",
    "    plt.clf()\n",
    "    packet = a[round((packet_num)*(fs/fps)):round((packet_num + 1)*(fs/fps))]\n",
    "    wave_info = FFT(packet, fs)[:round((fs/2)/(fps))]\n",
    "    unz = list(zip(*wave_info))\n",
    "    intensities = unz[0]\n",
    "    frequencies = unz[1]\n",
    "    bin_data = []\n",
    "    for bin_ind in range(1, 100):\n",
    "        upper_lim = ((fs/2))*((bin_ind/100)**2)\n",
    "        lower_lim = ((fs/2))*(((bin_ind - 1)/100)**2)\n",
    "        new_data = (intensities[math.floor(upper_lim//(frequencies[1] - frequencies[0]))]/fps)*(upper_lim - lower_lim)\n",
    "        bin_data.append(new_data)\n",
    "    plt.plot(bin_data)\n",
    "    axes = plt.gca()\n",
    "    axes.set_ylim([0, k])\n",
    "    plt.savefig(str(2 * packet_num) + \".png\")\n",
    "    \n",
    "    \n",
    "    packet1 = a[round((packet_num + 1)*(fs/fps)):round((packet_num + 2)*(fs/fps))]\n",
    "    wave_info1 = FFT(packet1, fs)[:round((fs/2)/(fps))]\n",
    "    unz1 = list(zip(*wave_info1))\n",
    "    intensities1 = unz1[0]\n",
    "    frequencies1 = unz1[1]\n",
    "    bin_data1 = []\n",
    "    for bin_ind1 in range(1, 100):\n",
    "        upper_lim1 = ((fs/2))*((bin_ind1/100)**2)\n",
    "        lower_lim1 = ((fs/2))*(((bin_ind1 - 1)/100)**2)\n",
    "        new_data1 = (intensities1[math.floor(upper_lim1//(frequencies1[1] - frequencies1[0]))]/fps)*(upper_lim1 - lower_lim1)\n",
    "        bin_data1.append(new_data1)\n",
    "        \n",
    "    smooth_bin = []\n",
    "    for smoothened_bin_ind in range(99):\n",
    "        smooth_bin.append((bin_data[smoothened_bin_ind] + bin_data1[smoothened_bin_ind])/2)\n",
    "        \n",
    "    plt.clf()\n",
    "    plt.plot(smooth_bin)\n",
    "    axes = plt.gca()\n",
    "    axes.set_ylim([0, k])\n",
    "    plt.savefig(str(2 * packet_num + 1) + \".png\")\n",
    "    \n",
    "    \n",
    "    plt.clf()\n",
    "    plt.plot(bin_data1)\n",
    "    axes = plt.gca()\n",
    "    axes.set_ylim([0, k])\n",
    "    plt.savefig(str(2 * packet_num + 2) + \".png\")\n",
    "#     clear_output(wait=True)\n",
    "!ffmpeg -r 30 -f image2 -s 432x288 -i %d.png -i tst.mp3 -vcodec libx264 -crf 25  -pix_fmt yuv420p -acodec copy tst.mp4\n",
    "!rm *.png\n",
    "#     TODO: Write pygame code to show bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('AudioVisualizer': conda)",
   "language": "python",
   "name": "python38564bitaudiovisualizerconda925d6ecf99d146b98f01d24ee3b8c5f9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}